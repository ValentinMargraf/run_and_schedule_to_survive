{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survival_tests.survival_curves import create_scenario, create_survival_curves, plot_survival_funcs\n",
    "from survival_tests.schedule import ground_truth_evaluation, survival_curve_from_schedule, termination_curve_from_train_data, compute_mean_runtime, schedule_termination_curve, normalized_par_k_values\n",
    "from survival_tests.optimization import run_optimization, solution_to_schedule\n",
    "from survival_tests.save_results import get_optimization_results, save_optimization_results, save_schedule_comparison, get_schedule_comparison, get_specific_optimization_results\n",
    "from survival_tests.evaluation_of_schedules import normalized_par_k, not_included_indices\n",
    "import survival_tests.optimization as survopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_name = 'QBF-2011'\n",
    "save = False\n",
    "PAR_K = 10\n",
    "instance_id = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = create_scenario(scenario_name, filepath='../../survival_tests/results/workspaces/aslib/')\n",
    "ALL_EVENT_TIMES, ALL_SURVIVAL_FUNCTIONS, CUTOFF, train_scenario, test_scenario = create_survival_curves(scenario, filename=scenario_name, filepath=\"survdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = not_included_indices(test_scenario)\n",
    "print(indices)\n",
    "print(len(ALL_EVENT_TIMES) - len(indices[0]), len(ALL_SURVIVAL_FUNCTIONS) - len(indices[0]))\n",
    "ALL_EVENT_TIMES = list(np.delete(ALL_EVENT_TIMES, indices, axis=0))\n",
    "ALL_SURVIVAL_FUNCTIONS = list(np.delete(ALL_SURVIVAL_FUNCTIONS, indices, axis=0))\n",
    "print(len(ALL_EVENT_TIMES), len(ALL_SURVIVAL_FUNCTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(np.array(ALL_EVENT_TIMES[instance_id]), np.array((ALL_SURVIVAL_FUNCTIONS[instance_id])), CUTOFF, save, filename= f\"graphs/{scenario_name}_inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TET, TTF = termination_curve_from_train_data(test_scenario.performance_data, CUTOFF)\n",
    "plot_survival_funcs(TET, TTF, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_values = np.min(test_scenario.performance_data.to_numpy(), axis=1)\n",
    "current_penalty = 10 * test_scenario.algorithm_cutoff_time\n",
    "np.where(perf_values==current_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions = {}\n",
    "# num_alg = len(ALL_EVENT_TIMES[0])\n",
    "# for instance_id in range(len(ALL_EVENT_TIMES)):\n",
    "#     survopt.EVENT_TIMES = ALL_EVENT_TIMES[instance_id]\n",
    "#     survopt.SURVIVAL_FUNCTIONS = ALL_SURVIVAL_FUNCTIONS[instance_id]\n",
    "#     survopt.CUTOFF = CUTOFF\n",
    "#     survopt.PAR_K = PAR_K\n",
    "\n",
    "#     solution = run_optimization(num_alg, CUTOFF, max_num_iteration=300)\n",
    "#     solutions[instance_id] = solution\n",
    "\n",
    "# save_optimization_results(solutions, scenario_name, PAR_K)\n",
    "\n",
    "solutions = get_optimization_results(scenario_name, PAR_K)\n",
    "solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data = test_scenario.performance_data.to_numpy()\n",
    "perf_data = np.delete(perf_data, indices, axis=0)\n",
    "\n",
    "if test_scenario.feature_cost_data is not None:\n",
    "    feature_cost_data = np.delete(test_scenario.feature_cost_data.to_numpy(), indices, axis=0)\n",
    "\n",
    "solutions_schedules = get_specific_optimization_results(scenario_name, PAR_K, 'variable')\n",
    "schedules = [solution_to_schedule(schedule, False) for schedule in solutions_schedules]\n",
    "\n",
    "schedule_result_on_ground_truths = []\n",
    "for idx in range(len(schedules)):\n",
    "    gtvalues = pd.DataFrame(perf_data[idx]).to_dict()[0]\n",
    "    gtvalues_schedule = ground_truth_evaluation(schedules[idx], gtvalues, CUTOFF, PAR_K * CUTOFF)\n",
    "\n",
    "    # Add feature cost to the runtime\n",
    "    if test_scenario.feature_cost_data is not None:\n",
    "        feature_time = feature_cost_data[idx]\n",
    "        accumulated_feature_time = np.sum(feature_time)\n",
    "        schedule_result_on_ground_truths.append(gtvalues_schedule + accumulated_feature_time)\n",
    "    else:\n",
    "        schedule_result_on_ground_truths.append(gtvalues_schedule)\n",
    "\n",
    "print(\"Unsolved Instances:\", len(np.where(np.array(schedule_result_on_ground_truths) >= CUTOFF)[0]))\n",
    "print(np.mean(schedule_result_on_ground_truths))\n",
    "normalized_par_k(schedule_result_on_ground_truths, train_scenario, test_scenario, PAR_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scenario.feature_cost_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schedules[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survival_tests.evaluation_of_schedules import mean_performance_of_singlebestssolver, mean_performance_of_virtualbestsolver\n",
    "print(mean_performance_of_virtualbestsolver(test_scenario, PAR_K))\n",
    "print(mean_performance_of_singlebestssolver(train_scenario, test_scenario, PAR_K))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the Single Best Schedule on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_termination_event_times, train_termination_curve = termination_curve_from_train_data(train_scenario.performance_data, train_scenario.algorithm_cutoff_time)\n",
    "plot_survival_funcs(train_termination_event_times, train_termination_curve, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_algs = len(train_termination_event_times)\n",
    "# survopt.SCENARIO = train_scenario\n",
    "# survopt.CUTOFF = CUTOFF\n",
    "# survopt.PAR_K = PAR_K\n",
    "# solution = run_optimization(num_algs, CUTOFF, max_num_iteration=250, survival=False)\n",
    "# Laufzeit steigt mit der Größe des Szenarios\n",
    "solution = {'function': 9314.446271648194, 'variable':[3188.4784125 ,  222.01027302 ,1441.84967197, 1169.78489849 ,2509.10583516]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = solution_to_schedule(solution)\n",
    "static_schedule_event_times, static_schedule_termination_values = schedule_termination_curve(schedule, CUTOFF, test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(static_schedule_event_times, static_schedule_termination_values, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_termination_event_times, test_termination_curve = termination_curve_from_train_data(test_scenario.performance_data, test_scenario.algorithm_cutoff_time)\n",
    "plot_survival_funcs(test_termination_event_times, test_termination_curve, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(test_termination_event_times + static_schedule_event_times, test_termination_curve + static_schedule_termination_values, CUTOFF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overseeable statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_algs = {f'Algorithm {i}':round(compute_mean_runtime(test_termination_event_times[i], test_termination_curve[i], CUTOFF, PAR_K)) for i in range(num_algs)}\n",
    "performance_algs = pd.Series(performance_algs)\n",
    "schedule_perf = {\"SingleBestSchedule\" : round(compute_mean_runtime(static_schedule_event_times[0], static_schedule_termination_values[0], CUTOFF, PAR_K))}\n",
    "schedule_perf = pd.Series(schedule_perf)\n",
    "result_table_on_inst = pd.concat([schedule_perf, performance_algs], sort=True)\n",
    "result_table_on_inst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nPARK for Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbsolver = mean_performance_of_virtualbestsolver(test_scenario, PAR_K)\n",
    "normalized_par_k_values(np.mean(schedule_result_on_ground_truths), result_table_on_inst[\"SingleBestSchedule\"], vbsolver)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBSchedule in Comparison to SBSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_par_k(result_table_on_inst[\"SingleBestSchedule\"], train_scenario, test_scenario, PAR_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of one testinstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_times, survival_functions = survival_curve_from_schedule(schedules[instance_id], ALL_EVENT_TIMES[instance_id], ALL_SURVIVAL_FUNCTIONS[instance_id], CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs([event_times], [survival_functions], CUTOFF, save, filename= f\"graphs/{scenario_name}_outputsPAR{PAR_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(list(ALL_EVENT_TIMES[instance_id]) + [event_times], list(ALL_SURVIVAL_FUNCTIONS[instance_id]) + [survival_functions], CUTOFF, save, filename= f\"graphs/{scenario_name}_comparisonPAR{PAR_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_data[instance_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules[instance_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtvalues = pd.DataFrame(perf_data[instance_id]).to_dict()[0]\n",
    "ground_truth_evaluation(schedules[instance_id], gtvalues, CUTOFF, PAR_K * CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of one schedule's performance on test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STET, STTF = schedule_termination_curve(schedules[instance_id], CUTOFF, test_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(STET, STTF, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_survival_funcs(TET + STET, TTF + STTF, CUTOFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on every problem instance considering the survival functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = len(ALL_EVENT_TIMES)\n",
    "num_algs = len(ALL_EVENT_TIMES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_on_inst = {f'Inst {inst}':{f'Algorithm {i}':round(compute_mean_runtime(ALL_EVENT_TIMES[instance_id][i], ALL_SURVIVAL_FUNCTIONS[instance_id][i], CUTOFF, inst)) for i in range(num_algs)} for inst in range(num_instances)}\n",
    "inst_performance = pd.DataFrame(performance_on_inst)\n",
    "inst_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_on_inst = {f'Inst {inst}': {\"Schedule\" : round(solutions[str(inst)]['function']) } for inst in range(num_instances)}\n",
    "schedule_perf = pd.DataFrame(schedule_on_inst)\n",
    "schedule_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table_on_inst = pd.concat([schedule_perf, inst_performance], sort=True)\n",
    "result_table_on_inst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARS = [PAR_K]\n",
    "algorithm_performace = {f'PAR{par}':{f'Algorithm {i}':round(compute_mean_runtime(ALL_EVENT_TIMES[instance_id][i], ALL_SURVIVAL_FUNCTIONS[instance_id][i], CUTOFF, par)) for i in range(len(ALL_EVENT_TIMES[instance_id]))} for par in PARS}\n",
    "table_algorithms = pd.DataFrame(algorithm_performace)\n",
    "table_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {f'PAR{PAR_K}': {\"Schedule\" : round(solutions[str(instance_id)]['function'])}}\n",
    "objective_table = pd.DataFrame(objectives)\n",
    "objective_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.concat([objective_table, table_algorithms], sort=True)\n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_schedule_comparison(scenario_name, PAR_K, scenario_properties=(ALL_EVENT_TIMES[instance_id], ALL_SURVIVAL_FUNCTIONS[instance_id], CUTOFF), curve_type='survival')\n",
    "# get_schedule_comparison(scenario_name, curve_type='survival')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance considering the ground truth runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_algorithm_performace = {f'PAR{par}':{f'Algorithm {i}':round(compute_mean_runtime(TET[i], TTF[i], CUTOFF, par)) for i in range(len(TET))} for par in PARS}\n",
    "termination_table_algorithms = pd.DataFrame(termination_algorithm_performace)\n",
    "termination_table_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_objectives = {f'PAR{PAR_K}': {\"Schedule\" : round(compute_mean_runtime(STET[0], STTF[0], CUTOFF, PAR_K))}}\n",
    "termination_objective_table = pd.DataFrame(termination_objectives)\n",
    "termination_objective_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_result_table = pd.concat([termination_objective_table, termination_table_algorithms], sort=True)\n",
    "termination_result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_schedule_comparison(scenario_name, PAR_K, scenario_properties=(TET, TTF, CUTOFF, STET, STTF), curve_type='termination')\n",
    "# get_schedule_comparison(scenario_name, curve_type='termination')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival_tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
